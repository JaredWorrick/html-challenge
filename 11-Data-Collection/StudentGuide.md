# Unit 11: Data Collection

## Objectives

* Identify HTML components in a website.

* Create a basic HTML document.

* Scrape data from a website by using Beautiful Soup.

* Use CSS selectors to scrape targeted elements.

* Use Chrome DevTools to identify elements and their CSS selectors.

* Use Splinter to perform automated browser actions.

* Automate the web scraping process by using Splinter and BeautifulSoup.

* Organize scraped information into a Python data structure.

## Helpful Links

* [Mozilla HTML Tutorials](https://developer.mozilla.org/en-US/docs/Learn/HTML)

* [Mozilla HTML Element documentation](https://developer.mozilla.org/en-US/docs/Web/HTML/Element)

* [HTML Standards](https://html.spec.whatwg.org/)

* [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

* [CSS Official Definition](https://www.w3.org/TR/CSS/#css)

* [Mozilla CSS Tutorials](https://developer.mozilla.org/en-US/docs/Learn/CSS)

* [Chrome DevTools Documentation](https://developer.chrome.com/docs/devtools/)

* [Splinter Documentation](https://splinter.readthedocs.io/en/latest/index.html)

- - -

Â© 2022 edX Boot Camps LLC. Confidential and Proprietary. All Rights Reserved.

